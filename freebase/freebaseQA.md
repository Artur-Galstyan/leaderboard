# freebaseQA

**freebaseQA**<sup>[[1]](#myfootnote1)</sup> is created for open-domain factoid question answering (QA) tasks over structured knowledge bases, like Freebase. Originally, it splits into 20,358 training, 3,994 eval and 3,996 test set.

This dataset can be downloaded via the [link](https://github.com/kelvin-jiang/FreebaseQA).


## Leaderboard 

|  Model / System  | Year | Exact Match | Accuracy | Language |                      Reported by                      |
|:----------------:|:----:|:-----------:|:--------:|:--------:|:-----------------------------------------------------:|
|       FAE        | 2022 |      -      |  63.30   |    EN     |  [Das et al.](https://arxiv.org/pdf/2202.10610.pdf)   |
|       EAE        | 2022 |      -      |  53.40   |    EN     |  [Das et al.](https://arxiv.org/pdf/2202.10610.pdf)   |
|     CBR-SUBG     | 2022 |      -      |  52.07   |    EN     |  [Das et al.](https://arxiv.org/pdf/2202.10610.pdf)   |
|      BuboQA      | 2022 |      -      |  38.25   |    EN     |  [Das et al.](https://arxiv.org/pdf/2202.10610.pdf)   |
|     FOFE-net     | 2019 |      -      |  37.00   |    EN     | [Jiang et al.](https://aclanthology.org/N19-1028.pdf) |
|   KBQA-Adapter   | 2022 |      -      |  28.78   |    EN     |  [Das et al.](https://arxiv.org/pdf/2202.10610.pdf)   |
|       KEQA       | 2022 |      -      |  28.73   |    EN     |  [Das et al.](https://arxiv.org/pdf/2202.10610.pdf)   |
|    HR-BiLSTM     | 2022 |      -      |  28.40   |    EN     |  [Das et al.](https://arxiv.org/pdf/2202.10610.pdf)   |
|  T5-XXL+WikiKG   | 2022 |    47.25    |    -     |    EN     |   [Moiseev et al.](https://arxiv.org/pdf/2205.08184.pdf)    |
|   T5-XXL+KELM    | 2022 |    45.90     |    -     |    EN     |   [Moiseev et al.](https://arxiv.org/pdf/2205.08184.pdf)    |
|      T5-XXL      | 2022 |    45.02    |    -     |    EN     |   [Moiseev et al.](https://arxiv.org/pdf/2205.08184.pdf)    |
|    T5-XXL+C4     | 2022 |    44.14    |    -     |    EN     |   [Moiseev et al.](https://arxiv.org/pdf/2205.08184.pdf)    |
| T5-large+WikiKG  | 2022 |    35.29    |    -     |    EN     |   [Moiseev et al.](https://arxiv.org/pdf/2205.08184.pdf)    |
|  T5-large+KELM   | 2022 |    34.16    |    -     |    EN     |   [Moiseev et al.](https://arxiv.org/pdf/2205.08184.pdf)    |
|   T5-large+C4    | 2022 |    34.01    |    -     |    EN     |   [Moiseev et al.](https://arxiv.org/pdf/2205.08184.pdf)    |
|     T5-large     | 2022 |    32.88    |    -     |    EN     |   [Moiseev et al.](https://arxiv.org/pdf/2205.08184.pdf)    |
|  T5-base+WikiKG  | 2022 |    28.38    |    -     |    EN     |   [Moiseev et al.](https://arxiv.org/pdf/2205.08184.pdf)    |
|    T5-base+C4    | 2022 |    28.33    |    -     |    EN     |   [Moiseev et al.](https://arxiv.org/pdf/2205.08184.pdf)    |
|   T5-base+KELM   | 2022 |    28.15    |    -     |    EN     |   [Moiseev et al.](https://arxiv.org/pdf/2205.08184.pdf)    |
|     T5-base      | 2022 |    27.55    |    -     |    EN     |   [Moiseev et al.](https://arxiv.org/pdf/2205.08184.pdf)    |



## References 
<a name="myfootnote1">[1]</a> Jiang, Kelvin et al. “FreebaseQA: A New Factoid QA Data Set Matching Trivia-Style Question-Answer Pairs with Freebase.” NAACL (2019).

[Go back to the README](../README.md)
