| System Name              | Reported by          | Reported in the paper                                                                                                                                                                        | Demo/Repo/API available | Link to Demo/Repo/API                                                                                                                  | Original paper                                                                                                                                                                                                           | System description                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Reference                                                                                                                                                                     |
| ------------------------ | -------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------- | -------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Alexandria               | Lopez et al.         | [Link](https://www.sciencedirect.com/science/article/pii/S157082681300022X?casa_token=NBVj-I48uxAAAAAA:izoYV-LubTYApUYRCtnZFPuvdACyWHHNnwVBjo1S1K24AiXYmMde9vdEBsCxdpAvlfNvPswrzr8#br000150) | not working             | [Link](http://alexandria.neofonie.de/)                                                                                                 | [Link](https://link.springer.com/chapter/10.1007/978-3-662-46641-4_8)                                                                                                                                                    | Alexandria is a German question answering system over a domain ontology that was built primarily with data from Freebase, Authors propose a new formal query building approach that consists of two stages. In the first stage, they predict the query structure of the question and leverage the structure to constrain the generation of the candidate queries and propose a novel graph generation framework to handle the structure prediction task and design an encoder-decoder model to predict the argument of the predetermined operation in each generative step. In the second stage, they follow the previous methods to rank the candidate queries. predict the query structure of the question and leverage the structure to constrain the generation of the candidate queries and propose a novel graph generation framework to handle the structure prediction task and design an encoder-decoder model to predict the argument of the predetermined operation in each generative step. In the second stage, they follow the previous methods to rank the candidate queries.            | Chen et al. only one triple, provide a modular, easy-toextend QA pipeline and evaluate it on the SimpleQuestionsWikidata benchmark. Ranking is learned from the training set. |
| Aqqu Wikidata (rules)    | Thomas Goette        | [Link](https://ad-publications.cs.uni-freiburg.de/theses/Master_Thomas_G√∂tte_2021.pdf)                                                                                                       | no                      | -                                                                                                                                      | [Link](https://ad-publications.cs.uni-freiburg.de/theses/Master_Thomas_G√∂tte_2021.pdf)                                                                                                                                   | Author focus on simple questions which means that the corresponding SPARQL query contains only one triple, provide a modular, easy-toextend QA pipeline and evaluate it on the SimpleQuestionsWikidata benchmark. Ranking with a set of weighted features.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | Thomas Goette                                                                                                                                                                 |
| AskNow                   | Diefenbach et al.    | [Link](http://www.semantic-web-journal.net/system/files/swj2038.pdf)                                                                                                                         | yes                     | [Link](https://github.com/AskNowQA)                                                                                                    | [Link](https://www.springerprofessional.de/en/asknow-a-framework-for-natural-language-query-formalization-in-s/10191942)                                                                                                 | Authors propose a framework, called AskNow, where users can pose queries in English to a target RDF knowledge base (e.g. DBpedia), which are first normalized into an intermediary canonical syntactic form, called Normalized Query Structure (NQS), and then translated into SPARQL queries. NQS facilitates the identification of the desire (or expected output information) and the user-provided input information, and establishing their mutual semantic relationship. At the same time, it is sufficiently adaptive to query paraphrasing. We have empirically evaluated the framework with respect to the syntactic robustness of NQS and semantic accuracy of the SPARQL translator on standard benchmark datasets.                                                                                                                                                                                                                                                                                                                                                                          | Dubey et al.                                                                                                                                                                  |
| BART                     | Chen et al.          | [Link](https://arxiv.org/pdf/2111.00732.pdf)                                                                                                                                                 | yes                     | [Link](https://github.com/pytorch/fairseq/blob/main/examples/bart/README.md)                                                           | [Link](https://arxiv.org/abs/1910.13461)                                                                                                                                                                                 | BART is a strong pre-trained sequence-tosequence model, that treats the problem of KGQA as a conventional machine translation task from NLQ to SPARQL.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | Lewis et al.                                                                                                                                                                  |
| BELA                     | Walter et al.        | [Link](https://download.hrz.tu-darmstadt.de/pub/FB20/Dekanat/Publikationen/UKP/76500354.pdf)                                                                                                 | no                      | -                                                                                                                                      | same as reporting paper                                                                                                                                                                                                  | Authors present a question answering system architecture whichprocesses natural language questions in a pipeline consisting of five steps:i) question parsing and query template generation, ii) lookup in an inverted index, iii) string similarity computation, iv) lookup in a lexicaldatabase in order to find synonyms, and v) semantic similarity computation                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | Walter et al.                                                                                                                                                                 |
| CASIA                    | He et al.            | [Link](http://nlpr-web.ia.ac.cn/cip/~liukang/liukangPageFile/QALD-3.pdf)                                                                                                                     | no                      | -                                                                                                                                      | same as reporting paper                                                                                                                                                                                                  | CASIA implements a basic pipeline framework which consists three main components, including question analysis, resource mapping and SPARQL generation. Inspecific, authors first employ shallow and deep linguistic analysis to transform NL-queriesinto a set of Query Triples with <subject, predict, object> format. Second, they mapeach phrase in Query Triple to the corresponding resource (class, entity, or property)in DBpedia. As a result, Ontology Triples are generated. Thirdly, the SPARQL querieswill be constructed based on Ontology Triple and question type. At last, the generatedSPARQL queries is used to search on the Linked Data, and the best answer can bepicked out through validating and ranking.                                                                                                                                                                                                                                                                                                                                                                       | He et al.                                                                                                                                                                     |
| DAM                      | Chen et al.          | [Link](https://arxiv.org/pdf/2111.00732.pdf)                                                                                                                                                 | no                      | -                                                                                                                                      | [Link](https://ur.booksc.me/book/82262350/2e40d5)                                                                                                                                                                        | Authors propose a transformer-based deep attentive semantic matching model (DAM), to identify the KB relations corresponding to the questions. The DAM is completely based on the attention mechanism and applies the fine-grained word-level attention to enhance the matching of questions and relations. On the basis of the DAM, we build a three-stage KBQA pipeline system                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | Chen et al.                                                                                                                                                                   |
| DEANNA                   | Diefenbach et al.    | [Link](http://www.semantic-web-journal.net/system/files/swj2038.pdf)                                                                                                                         | yes                     | [Link](https://www.mpi-inf.mpg.de/departments/databases-and-information-systems/research/yago-naga/deanna)                             | [Link](https://aclanthology.org/D12-1035.pdf)                                                                                                                                                                            | The method is based on an integer linear program to solve several disambiguation tasks jointly: the segmentation of questions into phrases; the mapping of phrases to semantic entities, classes, and relations; and the construction of SPARQL triple patterns. Our solution harnesses the rich type system provided by knowledge bases in the web of linked data, to constrain our semantic-coherence objective function.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | Yahya et al.                                                                                                                                                                  |
| DTQA                     | Omar et al.          | [Link](http://ceur-ws.org/Vol-2980/paper312.pdf)                                                                                                                                             | no                      | -                                                                                                                                      | [Link](https://ojs.aaai.org/index.php/AAAI/article/view/17988)                                                                                                                                                           | Authors demonstrate Deep Thinking Question Answering (DTQA), a semantic parsing and reasoning-based KBQA system. DTQA (1) integrates multiple, reusable modules that are trained specifically for their individual tasks (e.g. semantic parsing, entity linking, and relationship linking), eliminating the need for end-to-end KBQA training data; (2) leverages semantic parsing and a reasoner for improved question understanding.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | Abdelaziz et al.                                                                                                                                                              |
| ElNeuQA-ConvS2S          | Diomedi, Hogan       | [Link](https://arxiv.org/pdf/2107.02865.pdf)                                                                                                                                                 | yes                     | [Link](https://github.com/thesemanticwebhero/ElNeuKGQA)                                                                                | same as reporting paper                                                                                                                                                                                                  | Authors propose an approach, called ElNeuQA, that combines EL with NMT. Specifically, an EL system is used to identify entity mentions in the question and link them to the knowledge graph. They combine this with an NMT model that is trained and used to generate template queries with placeholders for entities. Also the model is strengthened with ConvS2S (Convolutional Sequence-to-Sequence): a CNN-based architecture, featuring gated linear units, residual connections, and attention.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | Diomedi, Hogan                                                                                                                                                                |
| Elon                     | Zheng et. al.        | [Link](https://arxiv.org/pdf/1910.09760.pdf)                                                                                                                                                 | yes                     | [Link](https://github.com/bszabo94/Elon), demo not working [Link](http://qald-beta.cs.upb.de:443/)                                     | same as reporting paper                                                                                                                                                                                                  | Elon by Szab¬¥o Bence et al. from Paderborn University in Germany stemsfrom a student project and is available at [Link](http://qald-beta.cs.upb.de:443/.It) is based on an own dictionary and not yet published.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | Zheng et. al.                                                                                                                                                                 |
| Frankenstein             | Liang et al.         | [Link](https://assets.researchsquare.com/files/rs-70794/v1_stamped.pdf)                                                                                                                      | yes                     | [Link](https://github.com/WDAqua/Frankenstein)                                                                                         | [Link](https://dl.acm.org/doi/fullHtml/10.1145/3178876.3186023)                                                                                                                                                          | Modern question answering (QA) systems need to flexibly integrate a number of components specialised to fulfil specific tasks in a QA pipeline. Since a number of different software components exist that implement different strategies for each of these tasks, it is a major challenge to select and combine the most suitable components into a QA system, given the characteristics of a question. The authors study this optimisation problem and train classifiers, which take features of a question as input and have the goal of optimising the selection of QA components based on those features and devise a greedy algorithm to identify the pipelines that include the suitable components and can effectively answer the given question. We implement this model within Frankenstein, a QA framework able to select QA components and compose QA pipelines. Evaluation results not only suggest that Frankenstein precisely solves the QA optimisation problem but also enables the automatic composition of optimised QA pipelines, which outperform the static Baseline QA pipeline. | Singh et al.                                                                                                                                                                  |
| gAnswer                  | Omar et al.          | [Link](http://ceur-ws.org/Vol-2980/paper312.pdf)                                                                                                                                             | not working             | [Link](http://59.108.48.18:8080/gAnswer/ganswer.jsp), [Link](http://ganswer.gstore-pku.com/)                                           | [Link](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8085196&casa_token=tKoH05rK3M0AAAAA:5fYhLLMidsRm4ibH-JoOaJst81ulY3_oS3crqTO_sLGAOjmVhQEFAvnTnd4v5ZpLqpsnIhhSF5k_&tag=1)                                      | Authors propose a semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is reduced to subgraph matching problem. They resolve the ambiguity of natural language questions at the time when matches of query are found. The cost of disambiguation is saved if there are no matching found. Two different frameworks to build the semantic query graph are proposed, gAnswer is relation (edge)-first.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | Hu et al.                                                                                                                                                                     |
| gAnswer2                 | Zheng et. al.        | [Link](https://arxiv.org/pdf/1910.09760.pdf)                                                                                                                                                 | no                      |                                                                                                                                        | [Link](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8085196)                                                                                                                                                     | Authors propose a semantic query graph to model the query intention in the natural language question in a structural way, based on which, RDF Q/A is reduced to subgraph matching problem. They resolve the ambiguity of natural language questions at the time when matches of query are found. The cost of disambiguation is saved if there are no matching found. Two different frameworks to build the semantic query graph are proposed, gAnswer2 is node-first.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | Hu et al.                                                                                                                                                                     |
| gGCN                     | Wu et al.            | [Link](https://arxiv.org/pdf/2101.01510.pdf)                                                                                                                                                 | no                      |                                                                                                                                        | same as reporting paper                                                                                                                                                                                                  | Authors present a relational graph convolutional network (RGCN)-based model gRGCN for semantic parsing in KBQA. gRGCN extracts the global semantics of questions and their corresponding query graphs, including structure semantics via RGCN and relational semantics (label representation of relations between entities) via a hierarchical relation attention mechanism.The gGCN model is obtained from gRGCN by replacing RGCN with Graph Convolutional Network (GCN)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              | Wu et al.                                                                                                                                                                     |
| GGNN                     | Sorokin and Gurevych | [Link](https://aclanthology.org/C18-1280.pdf)                                                                                                                                                | yes                     | [Link](https://github.com/UKPLab/coling2018-graph-neural-networks-question-answering)                                                  | same as reporting paper                                                                                                                                                                                                  | Authors address the problem of learning vector representations for complex semantic parses that consist of multiple entities and relations. For each input question, they construct an explicit structural semantic parse (semantic graph). Semantic parses can be deterministically converted to a query to extract the answers from the KB. To investigate ways to encode the structure of a semantic parse and to improve the performance for more complex questions, authors adapt Gated Graph Neural Networks (GGNNs), described in Li et al. (2016), to process and score semantic parses.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | Sorokin and Gurevych                                                                                                                                                          |
| GRAFT-Net                | Y Feng et al.        | [Link](https://arxiv.org/pdf/2112.06109.pdf)                                                                                                                                                 | yes                     | [Link](https://github.com/haitian-sun/GraftNet)                                                                                        | [Link](https://arxiv.org/abs/1809.00782)                                                                                                                                                                                 | Authors propose a novel graph convolution based neural network, called GRAFT-Net (Graphs of Relations Among Facts and Text Networks), specifically designed to operate over heterogeneous graphs of KB facts and text sentences. First, they propose heterogeneous update rulesthat handle KB nodes differently from the textnodes: for instance, LSTM-based updates are usedto propagate information into and out of text nodes. Second, authors introduce a directed propagation method, inspired by personalized Pagerankin IR (Haveliwala, 2002).                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   | Sun et al.                                                                                                                                                                    |
| GRAFT-Net + Clocq        | Christmann P. et al. | [Link](https://arxiv.org/pdf/2108.08597.pdf)                                                                                                                                                 | yes                     | [Link](https://github.com/PhilippChr/CLOCQ) (demo is available for further work on CLOCQ)                                              | same as reporting paper                                                                                                                                                                                                  | This work presents CLOCQ, an efficient method that prunes irrelevant parts of the search space using KB-aware signals. CLOCQ uses a top-ùëò query processor over score-ordered lists of KB items that combine signals about lexical matching, relevance to the question, coherence among candidate items, and connectivity in the KB graph.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | Christmann P. et al .                                                                                                                                                         |
| gRGCN                    | Wu et al.            | [Link](https://arxiv.org/pdf/2101.01510.pdf)                                                                                                                                                 | no                      |                                                                                                                                        | same as reporting paper                                                                                                                                                                                                  | Authors present a relational graph convolutional network (RGCN)-based model gRGCN for semantic parsing in KBQA. gRGCN extracts the global semantics of questions and their corresponding query graphs, including structure semantics via RGCN and relational semantics (label representation of relations between entities) via a hierarchical relation attention mechanism.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | Wu et al.                                                                                                                                                                     |
| Hakimov                  | Diefenbach et al.    | [Link](http://www.semantic-web-journal.net/system/files/swj2038.pdf)                                                                                                                         | no                      |                                                                                                                                        | [Link](https://www.semanticscholar.org/paper/Applying-Semantic-Parsing-to-Question-Answering-the-Hakimov-Unger/126ee532d48302b31f899ab392c51ad982ee5cad)                                                                 | Authors investigate how much lexical knowledge would need to be added so that a semantic parsing approach can perform well on unseen data. We manually add a set of lexical entries on the basis of analyzing the test portion of the QALD-4 dataset. Further, we analyze if a state-of-the-art tool for inducing ontology lexica from corpora can derive these lexical entries automatically.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Hakimov et al.                                                                                                                                                                |
| HR-BiLSTM                | Chen et al.          | [Link](https://arxiv.org/pdf/2111.00732.pdf)                                                                                                                                                 | no                      |                                                                                                                                        | [Link](https://arxiv.org/pdf/1704.06194.pdf)                                                                                                                                                                             | Authors propose a hierarchical recurrent neural network enhanced by residual learning which detects KB relations given an input question. The method uses deep residual bidirectional LSTMs to compare questions and relation names via different levels of abstraction. Additionally, they propose a simple KBQA system that integrates entity linking and our proposed relation detector to make the two components enhance each other                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Yu et al.                                                                                                                                                                     |
| Intui2                   | Diefenbach et al.    | [Link](http://www.semantic-web-journal.net/system/files/swj2038.pdf)                                                                                                                         | no                      |                                                                                                                                        | [Link](http://ceur-ws.org/Vol-1179/CLEF2013wn-QALD3-Dima2013.pdf)                                                                                                                                                        | The system takes as input a natural language question formulated in English and generates an equivalent SPARQL query. The mapping is based on the analysis of the syntactic patterns present in the input question.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | Corina Dima                                                                                                                                                                   |
| Intui3                   | Diefenbach et al.    | [Link](http://www.semantic-web-journal.net/system/files/swj2038.pdf)                                                                                                                         | no                      |                                                                                                                                        | [Link](http://ceur-ws.org/Vol-1180/CLEF2014wn-QA-Dima2014.pdf)                                                                                                                                                           | The system accepts as input a question formulated in natural language (in English), and uses syntactic and semantic information to construct its interpretation with respect to a given database of RDF triples (in this case DBpedia 3.9). The interpretation is mapped to the corresponding SPARQL query, which is then run against a SPARQL endpoint to retrieve the answers to the initial question.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Corina Dima                                                                                                                                                                   |
| ISOFT                    | Diefenbach et al.    | [Link](http://www.semantic-web-journal.net/system/files/swj2038.pdf)                                                                                                                         | no                      |                                                                                                                                        | [Link](http://ceur-ws.org/Vol-1180/CLEF2014wn-QA-ParkEt2014.pdf)                                                                                                                                                         | Authors use natural language processing tools to extract slots and SPARQL templates from the question and semantic similarity to map a natural language question to a SPARQL query.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | Park et al.                                                                                                                                                                   |
| KBQA-Adapter             | Oliya A et al        | [Link](https://aclanthology.org/2021.emnlp-main.345.pdf)                                                                                                                                     | yes                     | [Link](https://github.com/wudapeng268/KBQA-Adapter)                                                                                    | [Link](https://arxiv.org/pdf/1907.07328.pdf)                                                                                                                                                                             | In this paper, we propose a simple mapping method, named representation adapter, to learn the representation mapping for both seen and unseen relations based on previously learned relation embedding. The authors employ the adversarial objective and the reconstruction objective to improve the mapping performance                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Wu et al.                                                                                                                                                                     |
| KGQAn                    | Omar et al.          | [Link](http://ceur-ws.org/Vol-2980/paper312.pdf)                                                                                                                                             | yes                     | [Link](https://www.youtube.com/watch?v=Pdun0cG5PUE&ab_channel=RehamOsama)                                                              | same as reporting paper                                                                                                                                                                                                  | KGQAn transforms a question into semantically equivalent SPARQL queries via a novel three-phase strategy based on natural language models trained generally for understanding and leveraging short English text. Without preprocessing or annotated questions on KGs, KGQAn outperformed the existing systems in KG question answering by an improvement of at least 33% in F1-measure and 61% in precision                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             | Omar et al.                                                                                                                                                                   |
| KrantikariQA (Pairwise)  | G Maheshwari et. al. | [Link](https://arxiv.org/pdf/1811.01118.pdf)                                                                                                                                                 | yes                     | [Link](https://github.com/AskNowQA/KrantikariQA)                                                                                       | same as reporting paper                                                                                                                                                                                                  | Authors conduct an empirical investigation of neural query graph ranking approaches for the task of complex question answering over knowledge graphs. They experiment with six different ranking models and propose a novel self-attention based slot matching model which exploits the inherent structure of query graphs. Pairwise counterparts perform worse.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | G Maheshwari et. al.                                                                                                                                                          |
| KrantikariQA (Pointwise) | G Maheshwari et. al. | [Link](https://arxiv.org/pdf/1811.01118.pdf)                                                                                                                                                 | yes                     | [Link](https://github.com/AskNowQA/KrantikariQA)                                                                                       | same as reporting paper                                                                                                                                                                                                  | Authors conduct an empirical investigation of neural query graph ranking approaches for the task of complex question answering over knowledge graphs. They experiment with six different ranking models and propose a novel self-attention based slot matching model which exploits the inherent structure of query graphs. Pointwise models generally outperform their pairwise counterparts when trained on small datasets but have a comparable performance otherwise.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | G Maheshwari et. al.                                                                                                                                                          |
| LAMA                     | Radoev et. al.       | [Link](http://www.semantic-web-journal.net/system/files/swj2537.pdf)                                                                                                                         | no                      |                                                                                                                                        | same as reporting paper                                                                                                                                                                                                  | The proposed method is based on transforming natural language questions into SPARQL queries by leveraging the syntactic information of questions. Authors describe a set of lexico-syntactic patterns used to automatically generate triple patterns and SPARQL queries.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Radoev et. al.                                                                                                                                                                |
| Liang et al.             | Liang et al.         | [Link](https://assets.researchsquare.com/files/rs-70794/v1_stamped.pdf)                                                                                                                      | yes                     | [Link](https://github.com/Sylvia-Liang/QAsparql)                                                                                       | same as reporting paper                                                                                                                                                                                                  | Authors propose a new QA system for translating natural language questions into SPARQL queries. The key idea is to break up the translation process into 5 smaller, more manageable sub-tasks and use ensemble machine learning methods as well as Tree-LSTM-based neural network models to automatically learn and translate a natural language question into a SPARQL query.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Liang et al.                                                                                                                                                                  |
| LingTeQA                 | D. Nhuan et al.      | [Link](https://ieeexplore.ieee.org/abstract/document/9282949)                                                                                                                                | no                      |                                                                                                                                        | same as reporting paper                                                                                                                                                                                                  | Authors introduce a Question-Answering (QA) system that allows users to ask questions in English. The uniqueness of this system is its ability to answer questions containing linguistic terms, i.e., concepts such as SMALL, LARGE, or TALL. Those concepts are defined via membership functions drawn by users using a dedicated software designed for entering ‚Äòshapes‚Äô of these functions. The system is built based on an analogical problem solving approach, and is suitable for providing users with comprehensive answers.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | D. Nhuan et al.                                                                                                                                                               |
| Luo et al.               | Wu et al.            | [Link](https://arxiv.org/pdf/2101.01510.pdf)                                                                                                                                                 | no                      |                                                                                                                                        | [Link](https://aclanthology.org/D18-1242.pdf)                                                                                                                                                                            | Authors propose a neural network based approach to improve the performance of semantic similarity measurement in complex question answering. Given candidate query graphs generated from one question, their model embeds the question surface and predicate sequences into a uniform vector space. The main difference between their approach and previous methods is that the authors integrate hidden vectors of various semantic components and encode their interaction as the hidden semantics of the entire query graph. In addition, to cope with different semantic components of a query graph, dependency parsing information is leveraged as a complementary of sentential information for question encoding, which makes the model better align each component to the question.                                                                                                                                                                                                                                                                                                            | Luo et al.                                                                                                                                                                    |
| mBERT                    | Zhou Y. et al.       | [Link](https://aclanthology.org/2021.naacl-main.465.pdf)                                                                                                                                     | no                      |                                                                                                                                        | same as reporting paper                                                                                                                                                                                                  | A KGQA baseline, proposed in Zhou et al. for multilingual QA , implemented with fine-tuning pre-trained multilingual models (e.g. mBERT) in source language and directly perform inference in target language.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Zhou Y. et al.                                                                                                                                                                |
| MemNN                    | Oliya A et al        | [Link](https://aclanthology.org/2021.emnlp-main.345.pdf)                                                                                                                                     | no                      |                                                                                                                                        | [Link](https://arxiv.org/abs/1506.02075)                                                                                                                                                                                 | Authors present an embedding-based QA system developed under the framework of Memory Networks (MemNNs) (Weston et al., 2015; Sukhbaatar et al., 2015). Memory Networks are learning systems centered around a memory component that can be read and written to, with a particular focus on cases where the relationship between the input and response languages (here natural language) and the storage language (here, the facts from KBs) is performed by embedding all of them in the same vector space. The setting of the simple QA corresponds to the elementary operation of performing a single lookup in the memory.                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Bordes et al.                                                                                                                                                                 |
| MHE                      | Lopez et al.         | [Link](https://www.sciencedirect.com/science/article/pii/S157082681300022X?casa_token=NBVj-I48uxAAAAAA:izoYV-LubTYApUYRCtnZFPuvdACyWHHNnwVBjo1S1K24AiXYmMde9vdEBsCxdpAvlfNvPswrzr8#br000150) | no                      |                                                                                                                                        | no paper submitted, mentioned only in the organizers report                                                                                                                                                              | MHE is a method for retrieving entities from an entity graph given an input query in natural language. It was developed by Marek Ciglan at the Institute of Informatics at the Slovak Academy of Sciences. The method relies on query annotation, where parts of the query are labeled with possible mappings to the given knowledge base. The annotations comprise entities and relations, and were generated by means of a gazetteer, in order to expand relations with synonyms, and a Wikifier tool, in order to annotate entities. From those annotations, MHE constructs possible sub-graphs as query interpretation hypotheses and matches them against the entity graph of DBpedia. MHE was the onlyQALD-2 participant that provided answers to alltypes of questions, performing best on string anddate questions.                                                                                                                                                                                                                                                                             | Only in organizers' report.                                                                                                                                                   |
| Multi-hop QGG            | Zou et al.           | [Link](https://arxiv.org/pdf/2111.06086.pdf)                                                                                                                                                 | no                      |                                                                                                                                        | same as reporting paper                                                                                                                                                                                                  | Authors propose an end-to-end text-to-SPARQL baseline, which can effectively answer multitype complex questions, such as fact questions, dual-intent questions, boolean questions and counting questions, with Wikidata as the background knowledge base. The baseline's is implemented as relation-aware attention encoder and pointer network decoder.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                | Zou et al.                                                                                                                                                                    |
| NHGG                     | Chen et al.          | [Link](https://arxiv.org/pdf/2111.00732.pdf)                                                                                                                                                 | no                      |                                                                                                                                        | same as reporting paper                                                                                                                                                                                                  | Non-hierarchical Graph Generation (NHGG) integrates Outlining and Filling into one procedure. For AddVertex and AddEdge, the model directly predicts instances instead of classes. In this way, the query graph can be completed by only one decoding process without Filling operations.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | Chen et al.                                                                                                                                                                   |
| NSM                      | Y Feng et al.        | [Link](https://arxiv.org/pdf/2112.06109.pdf)                                                                                                                                                 | yes                     | [Link](https://github.com/RichardHGL/WSDM2021_NSM)                                                                                     | [Link](https://arxiv.org/pdf/2101.03737.pdf)                                                                                                                                                                             | Authors propose a novel teacher-student approach for the multi-hop KBQA task. In their approach, the student network aims to find the correct answer to the query, while the teacher network tries to learn intermediate supervision signals for improving the reasoning capacity of the student network. The major novelty lies in the design of the teacher network, where we utilize both forward and backward reasoning to enhance the learning of intermediate entity distributions. By considering bidirectional reasoning, the teacher network can produce more reliable intermediate supervision signals, which can alleviate the issue of spurious reasoning                                                                                                                                                                                                                                                                                                                                                                                                                                   | He et al.                                                                                                                                                                     |
| NSQA                     | P.Kapanipathi et al. | [Link](https://aclanthology.org/2021.findings-acl.339.pdf)                                                                                                                                   | no                      |                                                                                                                                        | same as reporting paper                                                                                                                                                                                                  | Authors propose Neuro-Symbolic Question Answering (NSQA), a modular KBQA system, that leverages (1) Abstract Meaning Representation (AMR) parses for task-independent question understanding; (2) a simple yet effective graph transformation approach to convert AMR parses into candidate logical queries that are aligned to the KB; (3) a pipeline-based approach which integrates multiple, reusable modules that are trained specifically for their individual tasks (semantic parser, entity and relationship linkers, and neuro-symbolic reasoner) and do not require end-to-end training data.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 | P.Kapanipathi et al.                                                                                                                                                          |
| NT-GRAFT-Net             | Y Feng et al.        | [Link](https://arxiv.org/pdf/2112.06109.pdf)                                                                                                                                                 | no                      |                                                                                                                                        | same as reporting paper                                                                                                                                                                                                  | Extension of NSM: authors replace NSM with GRAFT-Net in NT-NSMto create NT-GRAFT-Net and obtain 6.5-12.6%Hits@1 improvement on GRAFT-Net. GRAFT-Net is a novel graph convolution based neural network,called GRAFT-Net (Graphs of Relations AmongFacts and Text Networks), specifically designedto operate over heterogeneous graphs of KB factsand text sentences, proposed by Sun et al., 2018.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | Y Feng et al.                                                                                                                                                                 |
| NT-NSM                   | Y Feng et al.        | [Link](https://arxiv.org/pdf/2112.06109.pdf)                                                                                                                                                 | no                      |                                                                                                                                        | same as reporting paper                                                                                                                                                                                                  | Authors present NumericalTransformer on top of NSM, a state-of-the-art embedding-based KBQA model, to create NT-NSM. To enable better training, they propose two pre-training tasks with explicit numerical-oriented loss functions on two generated training datasets and a template-based data augmentation method for enriching ordinal constrained QA dataset.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Y Feng et al.                                                                                                                                                                 |
| O-Ranking                | Chen et al.          | [Link](https://arxiv.org/pdf/2111.00732.pdf)                                                                                                                                                 | no                      |                                                                                                                                        | same as reporting paper                                                                                                                                                                                                  | Outlining+Ranking (O-Rank) is an approach proposed by Chen et al. to generate AQG (Abstract Query Graph) by Outlining and subsequently produces the candidate graphs by enumerating the combination of instances to fill the AQG. Thereafter, the candidates are also ranked with CompQA.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | Chen et al.                                                                                                                                                                   |
| openQA                   | Marx et al.          | [Link](https://dl.acm.org/doi/abs/10.1145/2660517.2660519?casa_token=fiz_S3BfluoAAAAA:H0XJuhnjMIH5CH_y7lO6_I7xmCUo_1Of3wwQx0CyYB6adVDVxjrn0Rq3HSJUmfSG4cFAoG1cXN7_Iw)                        | yes                     | [Link](https://aksw.org/Projects/openQA.html)                                                                                          | same as reporting paper                                                                                                                                                                                                  | Authors present a modular and extensible open-source question answering framework and demonstrate how the framework can be used by integrating two state-of-the-art question answering systems.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | Marx et al.                                                                                                                                                                   |
| Platypus                 | Orogat et al.        | [Link](https://arxiv.org/pdf/2105.00811.pdf)                                                                                                                                                 | yes                     | [Link](https://askplatyp.us)                                                                                                           | same as reporting paper                                                                                                                                                                                                  | Platypus is an question answering platform which has been stoped maintaining after 2018. Platypus supports multilingual question answering by processing question in three steps: 1. convert natural question into internal logical representations. 2. rank the representations by their closeness to the correct interpretation of the question. 3. convert the representation into SPARQL query.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | Orogat et al.                                                                                                                                                                 |
| POMELO                   | Zhang et. al.        | [Link](https://ojs.aaai.org/index.php/AAAI/article/view/10381)                                                                                                                               | no                      |                                                                                                                                        | [Link](http://natalia.grabar.free.fr/publications/hamon-QALD2014.pdf)                                                                                                                                                    | Authors design a four-step method which pre-process the question, generation an abstraction of the question, then build a representation of the SPARQL query and finally generate the query.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            | Hamon et al.                                                                                                                                                                  |
| PowerAqua                | Lopez et al.         | [Link](https://arxiv.org/pdf/2105.00811.pdf)                                                                                                                                                 | yes                     | [Link](http://poweraqua.open.ac.uk:8080/poweraqua) (not working), demo: [Link](http://technologies.kmi.open.ac.uk/poweraqua/demo.html) | [Link](https://www.researchgate.net/publication/228963641_PowerAqua_Supporting_Users_in_Querying_and_Exploring_the_Semantic_Web_Content)                                                                                 | This QA system is built to fix searching and managing massive scale and heterogeneous content in knowledge base. It applys an ontology basedapproach to locate and integrate information.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               | Lopez et al.                                                                                                                                                                  |
| QAmp                     | Kapanipathi et al.   | [Link](https://aclanthology.org/2021.findings-acl.339.pdf)                                                                                                                                   | yes                     | [Link](https://github.com/svakulenk0/KBQA)                                                                                             | [Link](https://arxiv.org/pdf/1908.06917.pdf)                                                                                                                                                                             | QAmp is an approach to complex KGQA that uses unsupervised message passing, which propagates confidence scores obtained by parsing an input question and matching terms in the knowledge graph to a set of possible answers. First, we identify entity, relationship, and class names mentioned in a natural language question, and map these to their counterparts in the graph. Then, the confidence scores of these mappings propagate through the graph structure to locate the answer entities. Finally, these are aggregated depending on the identified question type.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | Vakulenko et al.                                                                                                                                                              |
| Qanary(TM+DP+QB)         | Orogat et al.        | [Link](https://arxiv.org/pdf/2105.00811.pdf)                                                                                                                                                 | yes                     | [Link](https://github.com/WDAqua/Qanary)                                                                                               | [Link](https://www.semanticscholar.org/paper/Frankenstein%3A-A-Platform-Enabling-Reuse-of-Question-Singh-Both/fe1538240c14fcf0de2507c9d6271fbaf38f22d5), [Link](https://dl.acm.org/doi/fullHtml/10.1145/3178876.3186023) | Qanary is a methodology for open question answering systems with the following attributes (requirements): interoperability, i.e., an abstraction layer for communication needs to be established, exchangeability and reusability, i.e., a component within a question answering system might be exchanged by another one with the same purpose, flexible granularity, i.e., the approach needs to be agnostic the processing steps implemented by a question answering system, isolation, i.e., each component within a QA system is decoupled from any other component in the QA system. In the cited pipeline, the following components were used: NED-tagme (for the entity recognition module), Diambiguation-Property-OKBQA (for the relationmapping module) and Query Builder (for the query generationmodule).                                                                                                                                                                                                                                                                                  |                                                                                                                                                                               |
| QAKiS                    | Zheng et. al.        | [Link](https://arxiv.org/pdf/1910.09760.pdf)                                                                                                                                                 | not working             | [Link](http://qakis.org/qakis2/), demo: [Link](https://www.youtube.com/watch?v=71ovvuoD354&ab_channel=WimmicsInria)                    | [Link](https://www.semanticscholar.org/paper/Querying-Multilingual-DBpedia-with-QAKiS-Cabrio-Cojan/409a7e40360b8199c4607740a5fad3989a9da07e)                                                                             | QAKiS exploits the alignment between properties carried out by DBpedia contributors as a mapping from Wikipedia terms to a common ontology, to exploit information coming from DBpedia multilingual chapters, broadening therefore its coverage.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | Cabrio et al.                                                                                                                                                                 |
